{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import vapeplot \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "--------------------\n",
    "\n",
    "The goal of this project is to make a classifier that predicts the final rankings for bakers.\n",
    "The idea is to make a model for each episode and to use data from previous episodes in the model.\n",
    "Therefore, a classifier for episode 1 will likely be bad at predicting the final outcome, but a classifier for episode 5 might accurately predict who will be in the top 3 and who might be eliminated in the next episode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Challenge Rankings\n",
    "--------------------------\n",
    "* tech_med : median technical challenge ranking over each episode\n",
    "* tech_mean : same as `tech_med` but the mean\n",
    "* tech : technical challenge ranking for that episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>baker</th>\n",
       "      <th>index</th>\n",
       "      <th>episode</th>\n",
       "      <th>tech_mean</th>\n",
       "      <th>tech_med</th>\n",
       "      <th>tech</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Annetha</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Annetha</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Annetha</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Annetha</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Annetha</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season    baker  index  episode  tech_mean  tech_med  tech  place\n",
       "0       1  Annetha      6        1       2.00       2.0     2      6\n",
       "1       1  Annetha      6        2       4.50       4.5     7      6\n",
       "2       1  Annetha      6        3       3.00       2.0     0      6\n",
       "3       1  Annetha      6        4       2.25       1.0     0      6\n",
       "4       1  Annetha      6        5       1.80       0.0     0      6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech = pd.read_csv(\"../RESULTS/gbbo.techinical.data.20190907.tsv\",sep='\\t')\n",
    "feats = ['tech_mean','tech_med','tech']\n",
    "tech.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is not scaled or normalized. \n",
    "\n",
    "Now apply a MinMax scaler so the minimum value is 0 and the maximum value is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tacitus/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = tech\n",
    "scaler = MinMaxScaler()\n",
    "# fit the scaler\n",
    "scaler.fit(mms[feats])\n",
    "# transform values\n",
    "mms[feats] = scaler.transform(mms[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tacitus/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2088: UserWarning: 'ignore_implicit_zeros' takes effect only with sparse matrix. This parameter has no effect.\n",
      "  warnings.warn(\"'ignore_implicit_zeros' takes effect only with\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qua = tech\n",
    "scaler = QuantileTransformer(\n",
    "    n_quantiles=10,\n",
    "    random_state=42,\n",
    "    ignore_implicit_zeros=True, #sparse matrix\n",
    ")\n",
    "# fit the scaler\n",
    "scaler.fit(qua[feats])\n",
    "# transform values\n",
    "qua[feats] = scaler.transform(qua[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE: 1   Training Set Length:  80\n",
      "EPISODE: 2   Training Set Length:  80\n",
      "EPISODE: 3   Training Set Length:  80\n",
      "EPISODE: 4   Training Set Length:  80\n",
      "EPISODE: 5   Training Set Length:  80\n",
      "EPISODE: 6   Training Set Length:  80\n",
      "EPISODE: 7   Training Set Length:  70\n",
      "EPISODE: 8   Training Set Length:  70\n",
      "EPISODE: 9   Training Set Length:  58\n",
      "EPISODE: 10   Training Set Length:  58\n"
     ]
    }
   ],
   "source": [
    "epi=sorted(list(set(tech['episode'])))\n",
    "for x in epi:\n",
    "    print('EPISODE:',x,\n",
    "          '  Training Set Length: ',\n",
    "          len(qua.loc[qua['episode']==x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Strategy\n",
    "---------------------\n",
    "For each episode, we evaluate the performance of classifier using two different methods.\n",
    "\n",
    "* Leave-One-Out (`loo`) \n",
    "\n",
    "* Stratified Cross Validation (`scv`)\n",
    "\n",
    "For `loo` we set aside 1 season as the test set, and train on the remaining seasons. We do this iteratively untill all seasons are evaluated. \n",
    "\n",
    "For `scv` we randomly subsample 1/5th of the dataset for testing and train on the remaining 4/5ths. Stratified means that random subsampling will keep the same proportion of class labels (here final rankings). Keeping the same proportion of class labels ensures that label is represented in the test and training sets. Like `loo`, this process is done iteratively so that each fold is evaluated. \n",
    "\n",
    "----------------\n",
    "\n",
    "#### Classifiers \n",
    "----------------\n",
    "\n",
    "We want to test the performance of different classifiers on our data. Different methods work better for different distributions of data (linear vs. non-linear). \n",
    "\n",
    "* Linear Support Vector Machine (SVM) \n",
    "* RBF SVM \n",
    "* Stochastic Gradient Descent (SGD)\n",
    "* K Nearest Neighbors\n",
    "* Gaussian Naive Bayes\n",
    "* Decision Trees\n",
    "* Random Forest\n",
    "* Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clfs = {\n",
    "    'Linear SVM' : SVC(kernel='linear'),\n",
    "    'RBF SVM' : SVC(kernel='rbf'),\n",
    "    'SGD' : SGDClassifier(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'Gaussian NB' : GaussianNB(),\n",
    "    'Descision Trees' : DecisionTreeClassifier(),\n",
    "    'Random Forest' : RandomForestClassifier(n_estimators=100),\n",
    "    'Neural Network' : MLPClassifier(hidden_layer_sizes=(100,30),max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation \n",
    "--------------------------\n",
    "Record the R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOO \n",
    "def gbbo_loo(df,clfs):\n",
    "    results={}\n",
    "    seasons = sorted(list(set(df['season'])))\n",
    "    for s in seasons:\n",
    "        # split test and training set\n",
    "        test = df.loc[df['season']==s].sample(frac=1.) # shuffles the data\n",
    "        train= df.loc[df['season']!=s].sample(frac=1.)\n",
    "        \n",
    "        episodes= sorted(list(set(df['episode'])))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
